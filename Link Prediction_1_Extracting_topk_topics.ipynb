{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "\n",
    "input: zmatrix file location, dimensions , number of users, number of topics, topn_topics\n",
    "<br> output: userId, topic id (topn topicId for each user)\n",
    "\n",
    "<br> STEPS\n",
    "<br> 1. Extracting zmatrix weights (sometimes all dimensions  are not filled in, hence add zero where a dimension value is not present\n",
    "<br> 2. Calculate z_matrix * transpose(z_matrix)\n",
    "<br> 3. Extract values from users(rows) and topic(0 to 100 columns)\n",
    "<br> 4. Write the results into file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "np.set_printoptions(suppress=True) \n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#please manually make sure all dimension values for all nodes, otherwise it will throw error\n",
    "\n",
    "def link_prediction(file_location, dimension, number_of_users, number_of_topics,topn):\n",
    "    #create an empty array for zmatrix\n",
    "    total_nodes = number_of_users + number_of_topics\n",
    "    zmatrix=np.zeros((total_nodes,dimension))\n",
    "    #read the file\n",
    "    f = open(file_location, \"r\")\n",
    "    f.readline()\n",
    "    i=0\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        row_array = line.split(':')\n",
    "        \n",
    "        #skip the first element of row_array\n",
    "#         str1 = ''.join(row_array[0])\n",
    "#         node, num_of_nodes = str1.split(',')\n",
    "        del row_array[0]\n",
    "        #each element in a line\n",
    "        weight=np.zeros(dimension)\n",
    "  \n",
    "        for index, pair in enumerate(row_array): \n",
    "            x1,x2 = pair.split(\",\")\n",
    "            #print(type(index),type(x1), type(x2))\n",
    "            x1 = int(x1)\n",
    "            x2 = float(x2)\n",
    "            #print(index,x1,x2)\n",
    "            #take only the second value, which is weight\n",
    "            #append the weight\n",
    "            weight[x1]=x2\n",
    "        #after complting one row, add to zmatrix    \n",
    "        zmatrix[i] = weight\n",
    "        i=i+1\n",
    "    f.close()\n",
    "    \n",
    "    #print(zmatrix)\n",
    "    np.savetxt('updated_zmatrix', zmatrix, delimiter=',')   # X is an array\n",
    "    \n",
    "    #calculate dot product\n",
    "    #get the transpose\n",
    "    zmatrix_t = np.transpose(zmatrix)\n",
    "    #dot product \n",
    "    result = np.dot(zmatrix,zmatrix_t)\n",
    "    \n",
    "    #save the result to file\n",
    "    folder, file = file_location.split('/')\n",
    "    file_zproduct =  folder + '/zproduct.csv'\n",
    "    file_ptr = open(file_zproduct, 'w')\n",
    "    np.savetxt(file_ptr, result, fmt='%10.10f', delimiter=\"\\t\")\n",
    "    file_ptr.close()\n",
    "    \n",
    "    #read the results from zproduct.csv\n",
    "    names=['UserId', 'TopicId', 'Weight']\n",
    "    headers = np.arange(0,total_nodes,1)\n",
    "    df_result = pd.read_csv(file_zproduct, sep='\\t', names=headers) \n",
    "    \n",
    "    #print(df_result)\n",
    "       \n",
    "    #read only users. For example stats from 100\n",
    "    df_result = df_result.iloc[number_of_topics:number_of_topics + number_of_users,:]\n",
    "    \n",
    "    #consume only first k columns as topics\n",
    "    df_result = df_result.iloc[:,0:number_of_topics]\n",
    "    \n",
    "    #skipped the normalised as we are focused on top k highest weight than actual prediction of weights\n",
    "    #find n largest weights and their index \n",
    "    #delete the content if file_name already exists\n",
    "    file_predicted = folder + '/predicted.csv'\n",
    "    open(file_predicted, 'w').close()\n",
    "    for index, row_user in df_result.iterrows():\n",
    "        #print((row_user.nlargest(5)))\n",
    "        #print(row_user)\n",
    "        top_n = row_user.nlargest(topn)\n",
    "        topics= top_n.index\n",
    "        weights=top_n.values\n",
    "\n",
    "        # create a dataframe with these values\n",
    "        topn_userinterest=pd.DataFrame({'UserId': np.repeat(index, topn), 'TopicId':topics,'Weight':weights})\n",
    "        topn_userinterest.to_csv(file_predicted, encoding='utf-8', index=False, sep='\\t', mode='a', header=False)\n",
    "        #print(topn_userinterest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted topk topics, Please wait...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# def link_prediction(file_location, dimension, number_of_users, number_of_topics,topn):\n",
    "print(\"Predicted topk topics, Please wait...\")\n",
    "link_prediction(\"Z_All_t4_c100/Zmatrix59\", 100,2458,100,10)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
